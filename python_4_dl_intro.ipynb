{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kytk/AI-MAILs/blob/main/python_4_dl_intro.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XvPA3O6r23RG"
      },
      "source": [
        "# 医療従事者のためのPython: 深層学習入門\n",
        "\n",
        "根本清貴 (筑波大学医学医療系精神医学)\n",
        "Ver. 20240726"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PApTxogz23RJ"
      },
      "source": [
        "## 本セクションの目標\n",
        "- 深層学習の概要について理解する\n",
        "- 深層学習にまつわるキーワードを理解する"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "skg1QOS823RK"
      },
      "source": [
        "## 参考書\n",
        "\n",
        "| Francois Chollet | 斎藤 勇哉 | 斎藤 康毅 |\n",
        "| :--: | :--: | :--: |\n",
        "| PythonとKerasによる<br>ディープラーニング 第2版 | 動かしながら学ぶ<br>PyTorchプログラミング入門 | ゼロから作るDeep Learning |\n",
        "| <img src=\"https://www.nemotos.net/nb/img/keras_2nd_cover.jpg\" width=\"100\"> | <img src=\"https://www.nemotos.net/nb/img/pytorch_cover.jpg\" width=\"100\"> | <img src=\"https://www.nemotos.net/nb/img/dl_from_scratch_cover.png\" width=\"100\"> |"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4TngKThr23RL"
      },
      "source": [
        "## 目次\n",
        "1. 人工知能, 機械学習, 深層学習\n",
        "2. 深層学習の概要\n",
        "    - 2-1. ニューラルネットワークの最小単位\n",
        "    - 2-2. 深層学習 の流れ\n",
        "    - 2-3. 隠れ層 hidden layer の意義\n",
        "    - 2-4. 全結合層 Fully-connected layer / Dense layer\n",
        "    - 2-5. 活性化関数\n",
        "    - 2-6. 画像および教師データの変形\n",
        "    - 2-7. 損失関数\n",
        "    - 2-8. オプティマイザ (最適化関数)\n",
        "    - 2-9. バッチ処理\n",
        "3. 畳み込みニューラルネットワーク\n",
        "4. 深層学習専用のフレームワーク"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lTgifa5C23RL"
      },
      "source": [
        "## 1. 人工知能, 機械学習, 深層学習\n",
        "\n",
        "| <img src=\"https://www.nemotos.net/nb/img/ai_ml_dl.png\" width=\"500\"> |\n",
        "| ---: |\n",
        "| 「PythonとKerasによるディープラーニング」より引用 |"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rRIl2nBP23RL"
      },
      "source": [
        "| 日本語名 | 英語名 | 略語 |\n",
        "| :-- | :-- | :-- |\n",
        "| 人工知能 | Artificial Intelligence | AI |\n",
        "| 機械学習 | Machine Learning | ML |\n",
        "| 深層学習 | Deep Learning | DL |\n",
        "\n",
        "- 人工知能: 「本来ならば人が行う知的な作業を自動化する取り組み」いちばん広い概念\n",
        "- 機械学習: 「特定のタスクの実行方法をコンピュータが学習する」\n",
        "    - 従来のプログラミング\n",
        "        - 人が「ルール」と「データ」を準備し、コンピュータはルールに従ってデータを処理する\n",
        "    - 機械学習のプログラミング\n",
        "        - 人は「データ」と「データから期待される答え」を準備し、コンピュータは「ルール」を出力する。\n",
        "        - システムは「訓練」されながらルールの精度を高めていく\n",
        "\n",
        "| <img src=\"https://www.nemotos.net/nb/img/programming_paradigm.png\" width=\"500\"> |\n",
        "| ---: |\n",
        "| 「PythonとKerasによるディープラーニング」より引用 |\n",
        "    \n",
        "- 深層学習: 機械学習の一種であり、データの特徴がどう表現(representation)されるかを学習する枠組み\n",
        "    - 入力されたデータを、複数の「層」からなるネットワークを通す。各層は入力されたデータから「特徴量」を学習し、それを次の層に渡していく。入力層と出力層の間にある層は「隠れ層」と呼ばれる"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "m5lc6NAj23RM"
      },
      "source": [
        "## 2. 深層学習の概要\n",
        "\n",
        "### 2-1. ニューラルネットワークの最小単位\n",
        "- ニューラルネットワークの最小単位は、入力信号 $x$、バイアス(bias)、重み(weight)、活性化関数(activation function)、出力(かつ次の入力)信号 $y$ で構成される。図の○をユニットと呼ぶ\n",
        "\n",
        "<img src=\"https://www.nemotos.net/nb/img/minimal_component.png\" width=\"350\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "s5dveb6b23RN"
      },
      "source": [
        "- 第1層にある 信号 $x$ が次の層に渡される時、重みを掛けることで重みづけがされる。重み weight は $w$ で表す。そして、$xw$ の結果に対し、さらにバイアス $b$ を付加する。一部のニューラルネットワークにはハンデを与えるようなイメージである。バイアス bias は $b$ として表す。この場合、次の層に行く信号は、$xw + b$ で表される\n",
        "- 第2層には関数が準備されている。先程の $xw + b$ がこの関数で処理され、その結果、出力信号 $y$ となる。この関数を、**活性化関数 activation function** という。上の図は、数式で表すならば、$ y = a(xw + b)$ と表される\n",
        "- 実際は、$y$ が次の層への入力となる。第2層が **隠れ層 hidden layer** の場合、頭文字をとって $h$ と表される"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gWpataqJ23RN"
      },
      "source": [
        "### 2-2. 深層学習の流れ\n",
        "\n",
        "| <img src=\"https://www.nemotos.net/nb/img/dl_overview.png\" width=\"500\"> |\n",
        "| ---: |\n",
        "| 「PythonとKerasによるディープラーニング」より引用 |"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3Euo7Kr523RO"
      },
      "source": [
        "- 入力 $x$ は重み $w$ で重みづけされて第1層に入っていく。第1層で活性化関数で処理された値となる\n",
        "- 第1層で処理された値は、別の重みで重みづけされて第2層に入っていく。第2層以降でも別の活性化関数で処理される\n",
        "- これらを繰り返し、最後に予測値 $y'$ が出力される\n",
        "    - 上の3つの流れを、**順伝播 forward propagation** という \n",
        "- 予測値 $y'$ は 真の値 $y$ と比較される\n",
        "- 予測値と真の値を **損失関数 loss function** で処理することで、**損失値 loss** を算出する\n",
        "- 損失値が0に近づけば近づくほど、モデルは正確となる\n",
        "- 損失関数を最小にするように重みを更新する\n",
        "    - 上の4つの流れを、**逆伝播 backward propagation** という\n",
        "- 順伝播と逆伝播を繰り返し、パラメータが適切な値に収束したら、別のデータセットを使用して、そのモデルが妥当かどうかを評価する。これを**バリデーション validation** という"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YARPpnxe23RO"
      },
      "source": [
        "### 2-3. 隠れ層 hidden layer の意義\n",
        "\n",
        "- ここで、隠れ層の意義について考えてみる\n",
        "\n",
        "<img src=\"https://www.nemotos.net/nb/img/dl_overview_1.png\" width=\"500\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sqVpyy1p23RO"
      },
      "source": [
        "#### 問題\n",
        "- 2つのベクトル $x_1$, $x_2$ と 5つの活性化関数 NOT, OR, NOR, AND, NAND を使って、以下のベクトル を表現してください\n",
        "\n",
        "| x1 | x2 |\n",
        "| :--: | :--: |\n",
        "| 0 | 0 |\n",
        "| 0 | 1 |\n",
        "| 1 | 0 |\n",
        "| 1 | 1 |"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yUhJT8sy23RO"
      },
      "source": [
        "- 活性化関数\n",
        "    - NOT: 0と1が入れ替わる\n",
        "    - OR: x1 と x2 の要素のどちらかが 1 ならば 1 (どちらが1でも1), どちらも 0 ならば 0\n",
        "    - NOR: OR の結果をNOTに代入する\n",
        "    - AND: x1 と x2 の要素のどちらも 1 ならば 1, それ以外は0\n",
        "    - NAND: AND の結果をNOTに代入する\n",
        "    \n",
        "\n",
        "| x1 | x2 | NOT(x2) | OR(x1,x2) | NOR(x1,x2) | AND(x1,x2) | NAND(x1,x2) |\n",
        "| -- | -- | -- | -- | -- | -- | -- |\n",
        "| 0 | 0 | 1 | 0 | 1 | 0 | 1 |\n",
        "| 0 | 1 | 0 | 1 | 0 | 0 | 1 |\n",
        "| 1 | 0 | 1 | 1 | 0 | 0 | 1 |\n",
        "| 1 | 1 | 0 | 1 | 0 | 1 | 0 |"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sSyHKOod23RP"
      },
      "source": [
        "#### 問題1. $y_1$ (簡単)\n",
        "\n",
        "| x1 | x2 |  | y1 |\n",
        "| -- | -- | -- | -- |\n",
        "| 0 | 0 |   | 1 |\n",
        "| 0 | 1 |   | 0 |\n",
        "| 1 | 0 |   | 0 |\n",
        "| 1 | 1 |   | 0 |\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wF7-R0bn23RS"
      },
      "source": [
        "- 図式にすると以下のように示せる\n",
        "\n",
        "<img src=\"https://www.nemotos.net/nb/img/nor_y1.png\" width=\"300\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "V4dAEyXG23RS"
      },
      "source": [
        "- NOR($x_1$,$x_2$) は下のようなグラフを書くための関数ともいえる\n",
        "\n",
        "| x1 | x2 | NOR(x1,x2) |\n",
        "| -- | -- | -- |\n",
        "| 0 | 0 | 1 (●) |\n",
        "| 0 | 1 | 0 (◆) |\n",
        "| 1 | 0 | 0 (◆) |\n",
        "| 1 | 1 | 0 (◆) |"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lRSF4eK523RS"
      },
      "source": [
        "<img src=\"https://www.nemotos.net/nb/img/nor_x1_x2_graph.png\" width=\"300\">\n",
        "\n",
        "- 直線で○と◇を2分割できるようなグラフはひとつの関数で書ける\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ne0vXjGP23RS"
      },
      "source": [
        "#### 問題2. $y_2$ (難しい)\n",
        "\n",
        "| x1 | x2 |  | y2 |\n",
        "| -- | -- | -- | -- |\n",
        "| 0 | 0 |   | 0 |\n",
        "| 0 | 1 |   | 1 |\n",
        "| 1 | 0 |   | 1 |\n",
        "| 1 | 1 |   | 0 |"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pUuaxWbV23RT"
      },
      "source": [
        "- $y_2$ はグラフで表すと以下のように示せる\n",
        "\n",
        "<img src=\"https://www.nemotos.net/nb/img/xor_graph.png\" width=\"300\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NE5u7rUS23RT"
      },
      "source": [
        "- この○と◇を2分割するには曲線を書くしかない\n",
        "\n",
        "<img src=\"https://www.nemotos.net/nb/img/xor_graph_with_line.png\" width=\"300\">\n",
        "\n",
        "- この問題を解くには、中間層を作る必要がある"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gfvk29OV23RT"
      },
      "source": [
        "| x1 | x2 |  | s1 = NAND(x1,x2) |\n",
        "| -- | -- | -- | -- |\n",
        "| 0 | 0 |   | 1 |\n",
        "| 0 | 1 |   | 1 |\n",
        "| 1 | 0 |   | 1 |\n",
        "| 1 | 1 |   | 0 |  \n",
        "\n",
        "<img src=\"https://www.nemotos.net/nb/img/x1_x2_nand_s1.png\" width=\"300\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "18q0bXM823RT"
      },
      "source": [
        "| x1 | x2 |  | s2 = OR(x1,x2) |\n",
        "| -- | -- | -- | -- |\n",
        "| 0 | 0 |   | 0 |\n",
        "| 0 | 1 |   | 1 |\n",
        "| 1 | 0 |   | 1 |\n",
        "| 1 | 1 |   | 1 |\n",
        "\n",
        "<img src=\"https://www.nemotos.net/nb/img/x1_x2_or_s2.png\" width=\"300\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "q6YFiQQX23RU"
      },
      "source": [
        "| s1 | s2 |  | y2 = AND(s1,s2) |\n",
        "| -- | -- | -- | -- |\n",
        "| 1 | 0 |   | 0 |\n",
        "| 1 | 1 |   | 1 |\n",
        "| 1 | 1 |   | 1 |\n",
        "| 0 | 1 |   | 0 |\n",
        "\n",
        "<img src=\"https://www.nemotos.net/nb/img/s1_s2_and_y2.png\" width=\"300\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jVwo1wPk23RU"
      },
      "source": [
        "- これらをすべてまとめると、以下になる\n",
        "\n",
        "<img src=\"https://www.nemotos.net/nb/img/nand_or_and_y2.png\" width=\"500\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WbpU6e7C23RU"
      },
      "source": [
        "- $x_1$, $x_2$ を **NAND**関数で処理した出力を $s_1$, **OR**関数で処理した出力を $s_2$ とした後、$s_1$, $s_2$ を入力データとして **AND**関数 で処理することにより、$y_2$ を求めることができた\n",
        "- 重み付けはしていない。$w$ はすべて1となる\n",
        "- 今の場合の $s_1$, $s_2$ に相当する層を 「**中間層**」 または 「**隠れ層**」 と呼ぶ\n",
        "- 深層学習は、隠れ層を上手に使うことによって、**データを線形だけでなく非線形に分類できる**\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SF7l4O5c23RU"
      },
      "source": [
        "### 2-4. 全結合層 Fully-connected layer / Dense layer\n",
        "- 全結合層の「層」はユニットのある層でなく、ユニットとユニットが結合されている層を指す\n",
        "- Dense層とも呼ばれる\n",
        "- 全結合層の定義：ある層における個々のユニットと、次の層にあるユニットがすべて連結している"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bRcwfAwJ23RU"
      },
      "source": [
        "<img src=\"https://www.nemotos.net/nb/img/fully_connected_layer.png\" width=\"400\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FM2C8cqS23RV"
      },
      "source": [
        "- 全結合層は、行列演算で簡単に表示することができる\n",
        "    - 結合の重みづけを w, バイアスを b で表示\n",
        "    \n",
        "<img src=\"https://www.nemotos.net/nb/img/weight_bias.png\" width=\"350\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0vA1TN9m23RV"
      },
      "source": [
        "- 深層学習でよく使われる w のルール\n",
        "    - 今いる層の 1番め のユニットと、前の層の 3番目 のユニットを結ぶ線の重みは、$w_{13}$ と表現する\n",
        "    - 重みを考える際、基準になる層は、データが「入ってくる」層\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "h_1 \\\\\n",
        "h_2 \\\\\n",
        "h_3\n",
        "\\end{bmatrix}\n",
        "= \n",
        "\\begin{bmatrix}\n",
        "1 & x_1 & x_2 & x_3\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "b_1 & b_2 & b_3 \\\\ \n",
        "w_{11} & w_{21} & w_{31}\\\\\n",
        "w_{12} & w_{22} & w_{32}\\\\\n",
        "w_{13} & w_{23} & w_{33}\n",
        "\\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "H6puZTco23RV"
      },
      "source": [
        "### 2-5. 活性化関数\n",
        "\n",
        "<img src=\"https://www.nemotos.net/nb/img/activation_function.png\" width=\"600\">\n",
        "\n",
        "- 深層学習によく用いられる活性化関数として、以下の3つが挙げられる\n",
        "    - **ReLU**関数: 隠れ層に用いられる\n",
        "    - **Sigmoid**関数: 2クラス分類の出力層に用いられる (犬/猫, 健常/疾患)\n",
        "    - **Softmax**関数: 多クラス分類の出力層に用いられる (数字の判別, 3クラス以上の判別)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0v7HkYtd23RV"
      },
      "source": [
        "- 活性化関数の特徴\n",
        "\n",
        "| 関数名 | 特徴 | \n",
        "| :-- | :-- |\n",
        "| ReLU | 隠れ層に使うことで、非線形問題を解くことができるようになる <br> Sigmoid関数は0-1の値しかとらないので層が厚くなるほど誤差が小さくなっていき、<br>入力層まで誤差が伝搬する前に誤差が消失するという勾配消失問題が発生する |\n",
        "| Sigmoid | 0-1の間の確率で表現可能なため、2クラス分類の出力層に用いる |\n",
        "| Softmax | 各クラスの確率の総和が1となるように正規化された関数であるため、多クラス分類の出力層に用いる |"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "H_3DqH6B23RV"
      },
      "source": [
        "#### ReLU関数\n",
        "- **Re**ctified **L**inear **U**nit 関数の略\n",
        "    - rectify: 整流する\n",
        "- 負の信号はすべて0とし、正の信号はそのままとする\n",
        "\n",
        "\n",
        "- 隠れ層で使われることが多い\n",
        "    - 計算式がシンプルなので処理が速い\n",
        "    - 0以下は0となるため、信号を発生しないユニットを表現できる\n",
        "\n",
        "\n",
        "- 数式では以下で表される\n",
        "\n",
        "$$\n",
        "relu(x) = \n",
        "\\begin{cases}\n",
        "x & (x > 0)\\\\\n",
        "0 & (x \\leq 0)\n",
        "\\end{cases}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R35FVwyj23RV"
      },
      "outputs": [],
      "source": [
        "# numpy を np としてインポート\n",
        "import numpy as np\n",
        "\n",
        "# matplotlib でグラフを描画するために matplotlib.pyplot を plt としてインポート\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vha-kxFU23RV"
      },
      "outputs": [],
      "source": [
        "# relu 関数を定義\n",
        "def relu(x):\n",
        "  return np.maximum(0, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "OzZ78CJ-23RV",
        "outputId": "982c14ce-d8d0-4b55-9a8f-7bdd94c23384"
      },
      "outputs": [],
      "source": [
        "# relu 関数を描画\n",
        "# xは-5.0から5.0まで0.1刻み\n",
        "x = np.arange(-5.0, 5.0, 0.1)\n",
        "y = relu(x)\n",
        "# x と y をプロット\n",
        "plt.plot(x, y)\n",
        "# グラフのタイトルを \"ReLU function\" に設定\n",
        "plt.title(\"ReLU function\")\n",
        "# いざ、描画\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uE55Lno023RW"
      },
      "outputs": [],
      "source": [
        "# ReLU の効果を実感してみる\n",
        "# 正規分布の 5 x 3 の行列を作成 np.random.randn で作成できる\n",
        "np.random.seed(seed=42) #皆が同じ結果を得ることができるようにする\n",
        "a = np.random.randn(5,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unFuq6Jq23RW",
        "outputId": "bde5cb6a-6896-469e-b1b6-7a4e1a9e92e9"
      },
      "outputs": [],
      "source": [
        "# aの内容を表示\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbV1tqbQ23RW",
        "outputId": "d7509f35-3118-4a8d-afc4-d5fcee23688a"
      },
      "outputs": [],
      "source": [
        "# relu 関数にかけると、負の値が 0 となり、それ以外はそのままであることがわかる\n",
        "relu(a)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xewLepCe23RW"
      },
      "source": [
        "#### Sigmoid関数\n",
        "\n",
        "- 以下の数式であらわされる関数であり、出力は0と1の間に収束する\n",
        "\n",
        "$$\n",
        "sigmoid(x) = \\frac{1}{1 + e^{-x}}\n",
        "$$\n",
        "\n",
        "- $x$ が大きくなる → $e^{-x}$ が小さくなる → 値は 1 に近づく\n",
        "- $x$ が小さくなる → $e^{-x}$ が大きくなる → 値は 0 に近づく\n",
        "\n",
        "\n",
        "- 2つのものを分類するような時に使われる\n",
        "    - 0.5以上だったら A, 0.5未満だったら B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp6tblEy23RW"
      },
      "outputs": [],
      "source": [
        "# sigmoid関数を定義\n",
        "def sigmoid(x):\n",
        "  return 1 / (1+np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "EgFRzKNy23RW",
        "outputId": "74b67e29-f589-4292-e390-d10193316d99"
      },
      "outputs": [],
      "source": [
        "# sigmoid関数を描画\n",
        "x = np.arange(-5.0, 5.0, 0.1)\n",
        "y = sigmoid(x)\n",
        "plt.plot(x, y)\n",
        "# y軸は -0.1 から 1.1 までの範囲に設定\n",
        "plt.ylim(-0.1, 1.1)\n",
        "plt.title(\"Sigmoid function\")\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WE8mXsyn23RW"
      },
      "source": [
        "#### Softmax関数\n",
        "- 主に多クラスの分類問題の出力層で使われる関数\n",
        "- 出力層がn個のユニットで構成される時、k番目の出力 $y_k$ は、数式では以下であらわされる\n",
        "\n",
        "$$\n",
        "y_k = \\frac{e^{a_k}}{\\sum_{i=1}^n e^{a_i}} = \\frac{e^{a_k}}{e^{a_1} + e^{a_2} + ... + e^{a_n}}\n",
        "$$\n",
        "\n",
        "\n",
        "- Softmax関数は、出力をすべて足すと 1 になることから、それぞれの出力を「確率」として扱える\n",
        "    - 出力層が4つのユニットから構成され、それぞれの出力が [0.1, 0.6, 0.1, 0.2] だとすると、「2番めのユニットが最も確率が高いので、答えは2番め」「答えは60%の確率で2番め、20%で4番目、10%で1番目か3番目」といったように表現できる\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "We6iggnN23RX"
      },
      "source": [
        "### 2-6. 画像および教師データの変形\n",
        "#### 画像の変換\n",
        "- 深層学習は大量のデータを扱う\n",
        "- 2次元画像は行列で表示されるが、大量に扱う時は、使い勝手が悪い\n",
        "- 全結合層のみの基本的なニューラルネットワークでは、1つの画像を1行の行列で表示する。こうすることで、多くの画像をひとつの行列で扱うことができる\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usSa8Hos23RX"
      },
      "outputs": [],
      "source": [
        "# 数字を 5x4 の行列で(画像として)表示してみる\n",
        "zero = np.array([[1,1,1,1],[1,0,0,1],[1,0,0,1],[1,0,0,1],[1,1,1,1]])\n",
        "one = np.array([[0,0,1,0],[0,0,1,0],[0,0,1,0],[0,0,1,0],[0,0,1,0]])\n",
        "two = np.array([[1,1,1,1],[0,0,0,1],[1,1,1,1],[1,0,0,0],[1,1,1,1]])\n",
        "three = np.array([[1,1,1,1],[0,0,0,1],[1,1,1,1],[0,0,0,1],[1,1,1,1]])\n",
        "four = np.array([[1,0,0,1],[1,0,0,1],[1,1,1,1],[0,0,0,1],[0,0,0,1]])\n",
        "five = np.array([[1,1,1,1],[1,0,0,0],[1,1,1,1],[0,0,0,1],[1,1,1,1]])\n",
        "\n",
        "# 0, 1, 2, 3, 4, 5 を nsets という3次元の配列に格納する\n",
        "nsets = np.array([zero,one,two,three,four,five])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5WIIVkd23RX",
        "outputId": "39bf78bf-a5d6-43cb-dd7d-f3dc3c906fb1"
      },
      "outputs": [],
      "source": [
        "# nsets は 6つの数字 x 5 x 4\n",
        "nsets.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RUYv3CQ23RX",
        "outputId": "6f61d53a-4843-49bb-9fdf-cf53ef75aefd"
      },
      "outputs": [],
      "source": [
        "# nsets の次元は 3次元\n",
        "nsets.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "6-BGoy3-23RX",
        "outputId": "17086333-d5a8-40b4-ac5b-ad9ae892857e"
      },
      "outputs": [],
      "source": [
        "# for ループを使って、それぞれの数字の配列を可視化する\n",
        "for i in nsets:\n",
        "    # 図のサイズを 1.25 x 1 インチに設定\n",
        "    plt.figure(figsize=(1.25,1))\n",
        "    # 配列 nsets の内容をひとつずつ表示\n",
        "    plt.imshow(i, cmap = 'gray')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "0GSrIQUG23RY",
        "outputId": "a870f9d6-9934-420c-ee05-f0c95b34d9ed"
      },
      "outputs": [],
      "source": [
        "# reshape メソッドを使うことで数字の 0 を1行で表示する\n",
        "# 今は 5 x 4 の行列のため、20の要素がある → 1行20列にしたい\n",
        "# reshape の 引数を -1 にすると、もうひとつの引数から推測してくれる\n",
        "\n",
        "# 変数 zero を 1行にしたものを zero_onerow に代入する\n",
        "zero_onerow = zero.reshape(1,-1) # zero.reshape(1,20) と同じ意味\n",
        "# 可視化してみる\n",
        "plt.imshow(zero_onerow,cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "EA6QBInR23RY",
        "outputId": "3d79ba03-07cd-4e9a-fc29-ffbf09d20d5a"
      },
      "outputs": [],
      "source": [
        "# nsets も同様に、全ての数字を1行で表示する\n",
        "# 数字が 6つ あるので、6行20列で今、ここにあるすべての数字を表現できる\n",
        "nsets_onerow = nsets.reshape(6,-1)\n",
        "plt.imshow(nsets_onerow,cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# 1行がひとつの数字をあらわす"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "5fN_zPrh23RY",
        "outputId": "3a03f0c8-2167-4d80-c3b9-223ccc5e6d51"
      },
      "outputs": [],
      "source": [
        "# reshape の特性から情報がきちんと保存されていることを確認\n",
        "# nsets の 3行目(インデックスは2)を取り出して変数 a に代入する\n",
        "a = nsets[2,:]\n",
        "# 5行4列に戻す\n",
        "b = a.reshape(5,4)\n",
        "# 可視化する\n",
        "plt.figure(figsize=(1.25,1))\n",
        "plt.imshow(b, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GKTNRyr923RY"
      },
      "source": [
        "#### 教師データの変換\n",
        "- 手書き数字の分類を行う場合、教師データは、シンプルに\"0\" \"1\" \"2\" という数字で提供されている\n",
        "- 深層学習では、この数字を **\"One-hot ベクトル\"** に変換する\n",
        "- One-hot とは、「ひとつだけホット、あとはコールド」という意味\n",
        "- ホットは 1, コールドは 0 で表現する\n",
        "- 数字の分類であれば、カテゴリ(クラスとも言う)は 10 (0-9)\n",
        "- 0, 1, 2, 3, 4, 5 を one-hot ベクトル に次のように変換する"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dIERsufY23RY"
      },
      "source": [
        "$$\n",
        "0 = \n",
        "\\begin{bmatrix}\n",
        "1 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0\n",
        "\\end{bmatrix}\n",
        "1 = \n",
        "\\begin{bmatrix}\n",
        "0 \\\\\n",
        "1 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0\n",
        "\\end{bmatrix}\n",
        "2 = \n",
        "\\begin{bmatrix}\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "1 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0\n",
        "\\end{bmatrix}\n",
        "3 = \n",
        "\\begin{bmatrix}\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "1 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0\n",
        "\\end{bmatrix}\n",
        "4 = \n",
        "\\begin{bmatrix}\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "1 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0\n",
        "\\end{bmatrix}\n",
        "5 = \n",
        "\\begin{bmatrix}\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "1 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0\n",
        "\\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hd75BNRW23RY"
      },
      "source": [
        "- こうすることで、Softmax関数の結果と照らし合わせることが可能となる\n",
        "\n",
        "$$\n",
        "softmax \\ output =\n",
        "\\begin{bmatrix}\n",
        "0.7 \\\\\n",
        "0.01 \\\\\n",
        "0.03 \\\\\n",
        "0.01 \\\\\n",
        "0.01 \\\\\n",
        "0.01 \\\\\n",
        "0.01 \\\\\n",
        "0.01 \\\\\n",
        "0.2 \\\\\n",
        "0.01\n",
        "\\end{bmatrix}\n",
        "one \\ hot \\ vector = \n",
        "\\begin{bmatrix}\n",
        "1 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0 \\\\\n",
        "0\n",
        "\\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RSwyUN8b23RZ"
      },
      "source": [
        "### 2-7. 損失関数\n",
        "- 損失関数 loss function: 予測値と真の値の違いを表現する関数\n",
        "    - 脳画像解析の世界では cost function と呼ばれるものと同じ\n",
        "- 損失関数の出力: 損失値 loss\n",
        "    - 損失値 loss が最小になれば、予測値は真の値に近づく\n",
        "- 損失関数には複数あるが、代表的なものとして、2乗和誤差と交差エントロピー誤差を紹介\n",
        "- 損失関数の使い分け\n",
        "\n",
        "| 目的 | 関数名 | Function Name | 損失関数名<br>(Tensorflow) | 損失関数名(PyTorch) |\n",
        "| :-- | :-- | :-- | :-- | :-- |\n",
        "| 回帰 | 平均二乗誤差 | Mean Squared Error | mean_squared_error | nn.MSELoss |\n",
        "| 2クラス分類 | バイナリ交差エントロピー | Binary Cross Entropy | binary_crossentropy | nn.BCELoss |\n",
        "| 多クラス分類 | ソフトマックス交差エントロピー | Softmax Cross Entropy | categorical_crossentropy (one-hot vector用)<br> sparse_categorical_crossentropy | nn.CrossEntropyLoss |"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8TcmEeTW23RZ"
      },
      "source": [
        "<img src=\"https://www.nemotos.net/nb/img/dl_overview_2.png\" width=\"500\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0keUHFKq23RZ"
      },
      "source": [
        "#### 二乗和誤差 sum of squared error\n",
        "- k次元の予測値を $y_k$, 真の値(教師データ)を $t_k$ とすると、2乗和誤差は以下で表現される\n",
        "\n",
        "$$\n",
        "E = \\frac{1}{2}\\sum_k (y_k - t_k)^2\n",
        "$$\n",
        "\n",
        "- 各データに対して、「真の値と予測値の差分の2乗」を計算し、それを総和した値\n",
        "- $\\frac{1}{2}$ は微分する時に計算がしやすくなるような工夫\n",
        "- one hot ベクトルを使うと、すぐに計算できる"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4seAd7O823RZ"
      },
      "outputs": [],
      "source": [
        "# 損失関数として、2乗和誤差を定義\n",
        "def sum_of_squared_error(y,t):\n",
        "    return 0.5 * np.sum((y - t)**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "xmqZCzOG23RZ",
        "outputId": "36866bd7-3ed5-4d9f-bf10-9f2a5a130267"
      },
      "outputs": [],
      "source": [
        "# 1次元における2乗和誤差を描画\n",
        "x = np.arange(0,1,0.01)\n",
        "y = 0.5 * x**2\n",
        "plt.plot(x,y)\n",
        "plt.title('Sum of squared error')\n",
        "plt.xlabel(\"predict - true\")\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWZ0yDqG23RZ",
        "outputId": "51b6dcad-3653-47f0-c3fb-ca50db1c1053",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# 手書きの数字画像を認識させるモデルを考える\n",
        "# 出力層の活性化関数は Softmax関数\n",
        "# ここでの ya は上図の予測値 Y' に相当\n",
        "ya = np.array([[0.01],[0.03],[0.7],[0.1],[0.01],[0.01],[0.01],[0.02],[0.1],[0.01]])\n",
        "ya"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODYNArHX23RZ",
        "outputId": "5edf7a84-4549-452b-d5bf-507735a3bd56",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# 2 が正解の one-hot ベクトル t2 を生成\n",
        "# 上図での真の目的値 Y に相当\n",
        "t2 = np.array([[0],[0],[1],[0],[0],[0],[0],[0],[0],[0]])\n",
        "t2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47P_Voe723Ra",
        "outputId": "1057df6f-f93b-4e09-8d20-a9cf677e78f9"
      },
      "outputs": [],
      "source": [
        "# 損失関数に代入\n",
        "# この結果が、損失値となる\n",
        "sum_of_squared_error(ya,t2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEBV-R4T23Ra",
        "outputId": "ab705bba-26eb-43ad-bc59-9800c62d87d4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# 5 が正解の one-hot ベクトル t5 を生成し、\n",
        "# ya と t5 から損失を求める\n",
        "# この場合、t5 が真の目的値となる\n",
        "t5 = np.array([[0],[0],[0],[0],[0],[1],[0],[0],[0],[0]])\n",
        "t5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OpYrHD_23Ra",
        "outputId": "7433e687-96ad-47c5-d86e-99949b9796f7"
      },
      "outputs": [],
      "source": [
        "# 損失関数に代入\n",
        "# 正解が2のときよりはるかに大きい → 損失が大きい → モデルがよくない\n",
        "sum_of_squared_error(ya,t5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uummePiN23Ra"
      },
      "source": [
        "#### 交差エントロピー誤差 cross entropy error\n",
        "- 交差エントロピー誤差は、以下の数式で定義される\n",
        "\n",
        "$$\n",
        "E = -\\sum_{k=1}^n t_k log (y_k)\n",
        "$$\n",
        "\n",
        "- n クラスのデータセットがあり、教師データが one-hot ベクトルの場合、 $t_k$ は正解は 1, 不正解は 0 となる\n",
        "- k番目のクラスが正解とし、その時の予測確率を $y_k$ すると、その時の交差エントロピー誤差は以下となる\n",
        "\n",
        "$$\n",
        "E = -log(y_k)\n",
        "$$\n",
        "\n",
        "- つまり、交差エントロピー誤差は、予測値(確率)を対数変換したものであり、予測値が1に近づけば近づくほど小さくなる"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-y9NwSDA23Ra"
      },
      "outputs": [],
      "source": [
        "# 損失関数として、交差エントロピー誤差を定義\n",
        "def cross_entropy_error(y,t):\n",
        "    #yが0になると無限大に発散してしまうため、小さな値を足すことで\n",
        "    # 無限大に発散することを予防する\n",
        "    delta = 1e-7 # 1e-7 は '10 の -7乗' を意味する\n",
        "    return -np.sum(t * np.log(y + delta))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "oP0hYH6F23Ra",
        "outputId": "7d1dcd04-33ce-43b5-d3a1-f080f55079c7",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# 交差エントロピー誤差を描画\n",
        "x = np.arange(0,1,0.01)\n",
        "y = -np.log(x + 1e-7)\n",
        "plt.plot(x,y)\n",
        "plt.title('Cross-entropy error')\n",
        "plt.xlabel('output of softmax function')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUFeUekB23Ra",
        "outputId": "9a86e5fb-27d3-4262-b536-18300e95e6e7"
      },
      "outputs": [],
      "source": [
        "# 予測値 ya, 真の目的値 t2 に対して 交差エントロピー誤差を計算\n",
        "cross_entropy_error(ya,t2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2KI1Kop23Rb",
        "outputId": "c4553dab-d4b2-4ead-da95-78570ad29a99"
      },
      "outputs": [],
      "source": [
        "# 予測値 ya, 真の目的値 t5 に対して 交差エントロピー誤差を計算\n",
        "cross_entropy_error(ya,t5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MdEXwuAy23Rb"
      },
      "source": [
        "### 2-8. オプティマイザ (最適化関数)\n",
        "\n",
        "<img src=\"https://www.nemotos.net/nb/img/dl_overview_3.png\" width=\"500\">"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sRi_i7Bv23Rb"
      },
      "source": [
        "- 深層学習の究極のゴールは、「損失値を0にすること」\n",
        "- 損失を少しでも 0 に近づけるように重み付けパラメータを更新する\n",
        "- パラメータと損失値の関係は下図のように関数で表現できる\n",
        "\n",
        "| <img src=\"https://www.nemotos.net/nb/img/optimizer.png\" width=400> |\n",
        "| --: |\n",
        "| 「PythonとKerasによるディープラーニング」より引用 |"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gZJ_SX6K23Rb"
      },
      "source": [
        "- オプティマイザ(最適化関数)は最小値を見つける\n",
        "- 直感的な理解としては、関数を微分することで局所における傾きを求め、傾きが 0 になるところを探す\n",
        "- 微分だけでは、上図での極小値にトラップされてしまう可能性もある\n",
        "- 微分に加えて関数の勾配による速度と加速度で生み出される「モーメンタム」を考慮することで、その問題を回避する\n",
        "- ボールを落とした時にボールが坂道を転がりながら一番低いところにおさまっていくイメージ\n",
        "- このプロセスが back propagation 逆伝播\n",
        "\n",
        "| アルゴリズム | 大まかな説明 |\n",
        "| :-- | :-- |\n",
        "| 確率的勾配法 (SGD) | 勾配の分だけパラメータを減らす |\n",
        "| モーメンタムSGD | SGD + モーメンタム (速度と慣性) |\n",
        "| AdaGrad | 学習が進むほど学習率を小さくする |\n",
        "| RMSprop |\tAdaGrad + 直近の勾配ほど強く影響 |\n",
        "| Adam | モーメンタムSGD + RMSprop |"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t2b4lg7Z23Rb"
      },
      "source": [
        "### 2-9. バッチ処理\n",
        "\n",
        "- オプティマイザでパラメータを最適化する際に、一度に入力するデータ数をバッチサイズという\n",
        "- 以下のような特性があり、ミニバッチ学習がよく使われる\n",
        "\n",
        "| 学習方法 | 学習手順 (図は [DXCEL WAVE](https://di-acc2.com/analytics/ai/6320/) より引用) | \n",
        "| :-- | :-- |\n",
        "| バッチ学習 | <img src=\"https://www.nemotos.net/nb/img/batch_learning.jpg\" width=\"400\"> |\n",
        "| オンライン学習 | <img src=\"https://www.nemotos.net/nb/img/online_learning.jpg\" width=\"400\"> |\n",
        "| ミニバッチ学習 | <img src=\"https://www.nemotos.net/nb/img/minibatch_learning.jpg\" width=\"400\"> |\n",
        "\n",
        "\n",
        "| 学習方法 | バッチサイズ | メリット | デメリット |\n",
        "| :-- | :-- | :-- | :-- |\n",
        "| バッチ学習 | 全データセット| ・全データを使うので<br>結果は安定しやすい | ・パラメータを1回更新するのに<br>全データセットに対して勾配を計算するため、<br>処理速度が遅い<br>・データが新しく追加になるたびに計算を<br>し直さないといけない |\n",
        "| オンライン学習 | 1例 | ・リアルタイムでモデル<br>更新を頻繁に行う<br>ケースに適用しやすい | ・外れ値に影響され、<br>結果が不安定になりやすい |\n",
        "| ミニバッチ学習 | ある程度<br>まとまった数 | バッチ学習と<br>オンライン学習の中間 | |\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YE1hR8G8kIb4"
      },
      "source": [
        "## 3. 畳み込みニューラルネットワーク (Convolutional Neural Network; CNN)の基本的な理解\n",
        "- 全結合層のみによるニューラルネットワークは、入力されたものの「全体」から特徴量を学習する\n",
        "- 畳み込みニューラルネットワークは、入力されたものの「一部」の特徴量を学習することを繰り返す\n",
        "\n",
        "\n",
        "### 3-1. 畳み込みニューラルネットワークの特徴\n",
        "\n",
        "- 学習した局所パターンは、他の場所で出現しても認識される (translation-invariant: 平行移動不変性)\n",
        "    - 下の例では、28ピクセルx28ピクセルで構成されている手書きの4の画像から、CNNは、3ピクセルx3ピクセルから構成される局所の情報(画像の縁はどうなっているか、画像の質感はどのような感じかなど)を学習していく\n",
        "    - 局所で学習したものは、別の場所で登場したとしても、同様な情報として認識される(下図では、左下の2つの局所パターン、右上の2つの局所パターンはそれぞれ同じようなものとして認識される) → 学習効率がよくなる\n",
        "\n",
        "| <img src=\"https://www.nemotos.net/nb/img/local_patterns.png\" width=250> |\n",
        "| --: |\n",
        "| 「PythonとKerasによるディープラーニング」より引用 |\n",
        "\n",
        "- CNNは、局所パターンの空間的ヒエラルキー(spatial hierarchies)を学習できる\n",
        "    - 下の図では、猫の絵がまず入力されている\n",
        "    - CNNは、まず、第1層で、基本的な形状を学習する(画像の縁の形状など)\n",
        "    - 次に、第2層で、形状の組み合わせによるもう少し大きなパターンを学習する\n",
        "    - それらを繰り返した結果に対して、教師データから「猫」と学習する\n",
        "\n",
        "| <img src=\"https://www.nemotos.net/nb/img/spatial_hierarchy.png\" width=400> |\n",
        "| --: |\n",
        "| 「PythonとKerasによるディープラーニング」より引用 |\n",
        "\n",
        "- これらは、「畳み込み」と「プーリング」によって実現される\n",
        "- CNNの登場により、深層学習の精度が飛躍的に向上することになった\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 3-2. 畳み込み層\n",
        "\n",
        "（このセクションと次のセクションで用いる画像は、[定番のConvolutional Neural Networkをゼロから理解する](https://deepage.net/deep_learning/2016/11/07/convolutional_neural_network.html)より引用)\n",
        "\n",
        "- ある画像を0と1で表現した時に、以下のように表現できたとする\n",
        "\n",
        "<img src=\"https://deepage.net/img/convolutional_neural_network/5x5image.jpg\" width=\"400\">\n",
        "\n",
        "- この画像を、左上から3x3の小さな行列だけ見ていくこととする。その際、下図のようなフィルタをかけることとする\n",
        "\n",
        "<img src=\"https://deepage.net/img/convolutional_neural_network/filter.jpg\" width=\"350\">\n",
        "\n",
        "- 左上から、フィルタをあてて、元の画像の画素とフィルタの数値をかけ算して、その合計を新しい行列に入れ込み、フィルタを少しずつずらしていく(ストライド)。これによって得られた新しい行列を「特徴量マップ」と呼ぶ\n",
        "\n",
        "<img src=\"https://deepage.net/img/convolutional_neural_network/animated_convolution.gif\" width=\"400\">\n",
        "\n",
        "- このようにフィルタをストライドさせていくことによって元画像の情報が「畳み込まれて」いくことにより、畳み込み層と呼ばれる\n",
        "- ある画素の周囲9つの情報を取り込むことから、位置情報や周囲の画素との関係性を特徴として捉えることが可能になる\n",
        "\n",
        "- なお、もとの行列のサイズなどが正方行列でない場合など、フィルタが適切に計算できないことがる。このような場合は、「ゼロパディング」といって、もとの行列の周辺に0をしきつめて計算できるようにする\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 3-3. プーリング層\n",
        "\n",
        "- 畳み込み層で得られた特徴量マップに対し、マップを小分けにして、区域ごとに最大値や平均値を抽出する\n",
        "- 最大値を抽出する方法を 最大値プーリング という\n",
        "\n",
        "<img src=\"https://deepage.net/img/convolutional_neural_network/max_pooling.jpg\" width=\"500\">\n",
        "\n",
        "- これにより、画像の微小な位置変化に対しても頑健になる\n",
        "− 情報量を削減することもできる\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "5KWLHJdw0FXT",
        "outputId": "05805d06-2031-4348-af47-040e105f61fa"
      },
      "outputs": [],
      "source": [
        "# 脳画像を用いて実際に畳み込みと最大値プーリングを経験してみる\n",
        "\n",
        "# 画像を読み込むため、PillowパッケージからImageモジュールを使用\n",
        "from PIL import Image\n",
        "# ファイルの有無を確認するために、osモジュールを使用\n",
        "import os\n",
        "\n",
        "# 画像をダウンロードする\n",
        "# 画像がない場合のみダウンロードする\n",
        "if os.path.exists('./brain.png'):\n",
        "  pass\n",
        "else:\n",
        "  !wget 'https://www.nemotos.net/nb/img/brain.png' \n",
        "\n",
        "\n",
        "# 変数 im に画像をグレースケールで読み込む\n",
        "im = Image.open('brain.png').convert('L')\n",
        "\n",
        "# 変数 im を Numpy配列に変換\n",
        "brain = np.array(im)\n",
        "\n",
        "# 画素を正規化して、0-1の値にする\n",
        "brain = brain / 255.0\n",
        "\n",
        "# brain を表示\n",
        "plt.figure\n",
        "plt.imshow(brain,cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# 行列の大きさを確認\n",
        "# 400行338列の大きさの画像\n",
        "print('matrix size of brain.png is {}'.format(brain.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HahYfEiS2gB5",
        "outputId": "9da6023d-e6e5-4264-faa9-e364803d2a66"
      },
      "outputs": [],
      "source": [
        "# フィルタを準備する\n",
        "# フィルタは 3x3 の単位行列とする\n",
        "\n",
        "filter = np.array([[1,0,0],\n",
        "                   [0,1,0],\n",
        "                   [0,0,1]])\n",
        "print(filter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "uOZ8q32cUF7i",
        "outputId": "5b35295b-8907-4dc8-f519-9f9662ce0df3"
      },
      "outputs": [],
      "source": [
        "# 画像から、3x3の局所を取り出す\n",
        "# 今、23行〜25行、103行〜105行の行列を取り出す\n",
        "\n",
        "local_brain = brain[22:25,102:105]\n",
        "\n",
        "plt.figure(figsize=(1,1))\n",
        "plt.imshow(local_brain, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(local_brain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "_4Fo2F-1WG65",
        "outputId": "2d39d5ba-3775-45cb-9c41-9c69df2ca65d"
      },
      "outputs": [],
      "source": [
        "# 取り出した画像にフィルタをかける\n",
        "\n",
        "local_brain_filtered = local_brain * filter\n",
        "\n",
        "plt.figure(figsize=(1,1))\n",
        "plt.imshow(local_brain_filtered, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "print(local_brain_filtered)\n",
        "\n",
        "local_brain_feature = local_brain_filtered.sum()\n",
        "print('feature is {}'.format(local_brain_feature))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7Mkfl6y9Jdv",
        "outputId": "fbef9d7b-dc2a-4687-db40-c86a9d175bf3"
      },
      "outputs": [],
      "source": [
        "# 画像全体に対してフィルタを使って畳み込みを行う\n",
        "# ここではscipyパッケージのsignalモジュールに入っているconvolve2dを使って畳み込みを行う\n",
        "from scipy import signal as sp\n",
        "\n",
        "# 畳み込みを行った結果を brain_feature という変数に代入する\n",
        "brain_feature = sp.convolve2d(brain, filter, boundary='fill', mode='valid')\n",
        "\n",
        "# 行列数を確認\n",
        "# 398行336列\n",
        "# フィルターのサイズにもよるが、畳みこみはそこまで画像の大きさは変化させない\n",
        "print('matrix size of brain.png is {}'.format(brain_feature.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "slVWIoQJ3zro",
        "outputId": "42252d5b-0fc1-425e-cd94-44f0847911f2"
      },
      "outputs": [],
      "source": [
        "# 最大値プーリングを行う\n",
        "# ここではskimage.measureに入っているblock_reduceを使って行う\n",
        "# 5x5のカーネル で 最大値プーリングする (5x5のマスごとに最大値を抜き出す)\n",
        "\n",
        "import skimage.measure\n",
        "# brain_feature を 5x5で区切って、最大値を計算する。\n",
        "# 398行 / 5 = 79.6 → あまった行はそこの最大値を計算する\n",
        "# 336列 / 5 = 67.2 → 同様にあまった列はそこの最大値を計算する\n",
        "\n",
        "brain_pooled = skimage.measure.block_reduce(brain_feature, (5,5), np.max)\n",
        "\n",
        "# brain_pooled を表示\n",
        "# ぼやけているが、脳の形状は保持されている\n",
        "plt.figure\n",
        "plt.imshow(brain_pooled,cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# 行列数を確認\n",
        "# 80行68列\n",
        "# 最初に比べて情報量が削減された\n",
        "print('matrix size of brain.png is {}'.format(brain_pooled.shape))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2VwQS4H623Rb"
      },
      "source": [
        "## 4. 深層学習専用のフレームワーク\n",
        "- 深層学習をPythonで実装する場合、深層学習に特化したフレームワークを使うのが一般的\n",
        "- 2024年現在、2大巨頭は Tensorflow と PyTorch\n",
        "\n",
        "| フレームワーク | Tensorflow | PyTorch |\n",
        "| :--: | :-- | :-- |\n",
        "| 開発 | Google | Facebook |\n",
        "| 登場年| 2015年 | 2016年|\n",
        "| 特徴 | Kerasを使うことで実装しやすい | ロジックの把握がしやすく、研究方面に強い |\n",
        "\n",
        "- 今回は Tensorflow/Keras を使用\n",
        "- 基本をしっかり理解できれば PyTorch にもすんなり移行できるはず\n",
        "\n",
        "- 次のセクションで、実際にTensorflow/Keras を使って、手書き数字の識別にトライする"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "python_4_dl_intro.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
