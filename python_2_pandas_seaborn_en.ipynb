{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/kytk/AI-MAILs/blob/main/python_2_pandas_seaborn_en.ipynb?hl=en\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YoSBiFrTqj9e"
   },
   "source": [
    "# Python for Healthcare Professionals: Pandas and Seaborn\n",
    "\n",
    "Kiyotaka Nemoto (Department of Psychiatry, Faculty of Medicine, University of Tsukuba)\n",
    "\n",
    "Ver.20240703"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUNPeJViyEYm"
   },
   "source": [
    "## Reference Materials\n",
    "- [Pandas Official Documentation (English)](https://pandas.pydata.org/docs/index.html)\n",
    "- [Seaborn Official Documentation (English)](https://seaborn.pydata.org/tutorial/introduction)\n",
    "\n",
    "## Data Used Today\n",
    "- Diabetes Dataset https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
    "- The column names of the distributed file were edited and split into two Excel files\n",
    "- diabetes_demographics.xlsx: Age, Sex, BMI, Average Blood Pressure\n",
    "- diabetes_data.xlsx: T-Cho, LDL, HDL, T-Cho/HDL, Log of TG, Blood Sugar, Y (Progression over 1 year)\n",
    "\n",
    "## Goals of This Section\n",
    "- Be able to read Excel files using Pandas\n",
    "- Be able to extract specific columns or rows using Pandas\n",
    "- Be able to merge two files using Pandas\n",
    "- Be able to create various graphs using Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "1. Overview of Pandas and Seaborn\n",
    "2. Basics of Pandas\n",
    "   - Data loading\n",
    "   - Data display\n",
    "   - Data manipulation\n",
    "   - Data merging\n",
    "   - Handling missing values\n",
    "3. Basics of Seaborn\n",
    "   - Basic graphs\n",
    "   - Customization\n",
    "4. Quiz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BO_Iii-JyEYm"
   },
   "source": [
    "## 1. Overview of Pandas and Seaborn\n",
    "- Pandas\n",
    "    - A tool for data analysis and manipulation in Python\n",
    "    - \"Pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language.\"\n",
    "- Seaborn\n",
    "    - A tool for easily creating graphs from statistical data in Python\n",
    "    - \"Seaborn is a library for making statistical graphics in Python.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0. Installing Pandas and Seaborn (not necessary this time)\n",
    "- When setting up your own Python environment, install Pandas and Seaborn with the following:\n",
    "\n",
    "    ```\n",
    "    pip install pandas seaborn\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oakypyoGyEYp"
   },
   "source": [
    "### 1.1. Importing Pandas, Seaborn, and os\n",
    "- pandas is often imported as pd\n",
    "- seaborn is often imported as sns\n",
    "- We will also import the os module to check files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas is often imported as pd\n",
    "import pandas as pd\n",
    "\n",
    "# seaborn is often imported as sns (seaborn name space)\n",
    "import seaborn as sns\n",
    "\n",
    "# Import the os module to check files\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Loading Data into Google Colab\n",
    "- When working in Google Colab, you usually drag & drop data under \"Files\" on the left\n",
    "- You can then access it with 'filename'\n",
    "- Now, we will download and use the data\n",
    "- Executing the cell below will download three xlsx files\n",
    "- **Note**: Work content in Google Colab disappears after a certain time. To save data, you need to download work results periodically\n",
    "\n",
    "<img src=\"https://www.nemotos.net/nb/img/colabo_files.png\" width=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JmkGrITrtVp7"
   },
   "outputs": [],
   "source": [
    "# Download the data we'll use today\n",
    "# File names are diabetes_demographics.xlsx, diabetes_demographics_short.xlsx, diabetes_data.xlsx\n",
    "#\n",
    "# (Note: This is not essential for this lecture, so don't worry if you don't understand it)\n",
    "# ! is used when you want to execute a program in the shell from Python\n",
    "# [[ -f diabetes_demographics.xlsx ]] is a shell script test statement asking \"Is there a file called diabetes_demographics.xlsx?\"\n",
    "# || means \"if the return value is False, then...\"\n",
    "# wget is a Linux program for downloading\n",
    "\n",
    "![[ -f diabetes_demographics.xlsx ]] || wget https://raw.githubusercontent.com/kytk/AI-MAILs/main/data/diabetes_demographics.xlsx\n",
    "![[ -f diabetes_data.xlsx ]] || wget https://raw.githubusercontent.com/kytk/AI-MAILs/main/data/diabetes_data.xlsx\n",
    "![[ -f diabetes_data_short.xlsx ]] || wget https://raw.githubusercontent.com/kytk/AI-MAILs/main/data/diabetes_data_short.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can display a list of files under the current directory using the listdir() function in the os module\n",
    "# Confirm that the following three files are present:\n",
    "#   diabetes_demographics.xlsx\n",
    "#   diabetes_data.xlsx\n",
    "#   diabetes_data_short.xlsx\n",
    "\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basics of Pandas\n",
    "\n",
    "### 2.1. Examples of What Pandas Can Do\n",
    "- Handle tables\n",
    "- Output descriptive statistics of tables\n",
    "- Extract parts of tables\n",
    "- Merge multiple tables\n",
    "- Generate new columns from information in multiple columns\n",
    "- Pandas DataFrames can be used directly for graph creation in Seaborn\n",
    "\n",
    "### 2.2. Necessity of Pandas: Data Preprocessing and Cleaning\n",
    "- Data preprocessing is an important step in data analysis\n",
    "- Using Pandas, you can handle missing values, convert data types, remove duplicate data, etc.\n",
    "\n",
    "### 2.3. Pandas Terminology: \"DataFrame\"\n",
    "- Think of it as a general table\n",
    "- In Pandas, a single table is called a \"DataFrame\"\n",
    "- Row: row; Column: column\n",
    "- The name dataframe is often abbreviated and assigned to a variable called 'df'\n",
    "\n",
    "<img src=\"https://www.nemotos.net/nb/img/pandas_01.png\" width=400>\n",
    "Figure: Quoted from the official Pandas documentation\n",
    "\n",
    "### 2.4. Loading Data into Pandas\n",
    "- Pandas can read Excel files and CSV files\n",
    "- Excel files can be read with `pd.read_excel('excel_file')`\n",
    "- CSV files can be read with `pd.read_csv('csv_file')`\n",
    "- Specifying IDs etc. as an index makes handling easier\n",
    "\n",
    "- diabetes_demographics.xlsx\n",
    "\n",
    "    <img src=\"https://www.nemotos.net/nb/img/diabetes_demographics_screenshot.png\" width=300>\n",
    "\n",
    "- diabetes_data.xlsx\n",
    "\n",
    "    <img src=\"https://www.nemotos.net/nb/img/diabetes_data_screenshot.png\" width=450>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read diabetes_demographics.xlsx as df_demographics. Set the 0th column as the index column\n",
    "df_demographics = pd.read_excel('diabetes_demographics.xlsx',index_col=0)\n",
    "\n",
    "# Read diabetes_data.xlsx as df_data. Set the 0th column as the index column\n",
    "df_data = pd.read_excel('diabetes_data.xlsx',index_col=0)\n",
    "\n",
    "# Read diabetes_data_short.xlsx as df_data_short. Set the 0th column as the index column\n",
    "df_data_short = pd.read_excel('diabetes_data_short.xlsx',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the Overview of the DataFrame\n",
    "- You can find out what information is in the DataFrame using the info() method of the pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an overview of df_demographics\n",
    "df_demographics.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Categorical Data\n",
    "- Currently, SEX is int64, which is an integer type.\n",
    "- There is a way to change this to categorical data as follows:\n",
    "    ```\n",
    "    # Data type conversion\n",
    "    df_demographics['SEX'] = df_demographics['SEX'].astype('category')\n",
    "    ```\n",
    "- However, in this case, it tends to cause errors later, so we intentionally do not change it here\n",
    "- Caution is needed for the descriptive statistics that follow\n",
    "\n",
    "#### Pandas DataFrame Type\n",
    "- Pandas DataFrames are defined in their own type\n",
    "- The type of a pandas DataFrame can be known using the `type()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame type\n",
    "# pandas.core.frame.DataFrame type\n",
    "type(df_demographics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Displaying Data\n",
    "- If the loaded DataFrame is df, you can display the first 5 rows using the head() method\n",
    "    - Using head(10) will display 10 rows\n",
    "- The size of the table can be checked with df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first 5 rows of df_demographics\n",
    "\n",
    "# Note that the ID column is now the index column, so the ID is shifted one step\n",
    "df_demographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what happens if we don't specify the index column\n",
    "# ID is read as one variable\n",
    "# The index is 0, 1, 2 ... on the far left\n",
    "\n",
    "df_demo_without_index = pd.read_excel('diabetes_demographics.xlsx')\n",
    "df_demo_without_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the size of the df_demographics table\n",
    "# 442 rows and 4 columns excluding the index (ID)\n",
    "df_demographics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first 5 rows of df_data\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the size of the df_data table\n",
    "# 442 rows and 7 columns excluding the index (ID)\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first 5 rows of df_data_short\n",
    "# Data where ID is not a sequential number\n",
    "df_data_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the size of the df_data_short table\n",
    "# 252 rows and 7 columns excluding the index (ID)\n",
    "df_data_short.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6. Descriptive Statistics of Data\n",
    "- As Pandas claims to be a data analysis tool, it's easy to calculate descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe() calculates descriptive statistics for each item\n",
    "# For continuous values, it outputs the number of samples, mean, standard deviation, minimum, 25th percentile, 50th percentile, 75th percentile, and maximum in a list\n",
    "df_demographics.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the groupby() method, you can calculate descriptive statistics for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the groupby() method to calculate the mean for each sex\n",
    "df_demographics.groupby(by='SEX').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the corr() method, you can calculate correlation coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation can also be easily calculated with the corr() method\n",
    "# Calculate the correlation between each column of df_data\n",
    "\n",
    "# Display 3 rows of df_data\n",
    "df_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation\n",
    "df_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7. Data Manipulation (1)\n",
    "#### Extracting Columns\n",
    "- In Pandas, you can extract specific columns from data using column names\n",
    "- Python uses [] to extract elements. Following this principle, you can extract specific columns by using df['column_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column names of df_data can be obtained with df_data.columns\n",
    "df_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to extract only the 'T-Cho' column, use df_demographics['T-Cho']\n",
    "df_data['T-Cho']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also calculate the mean of just the extracted column\n",
    "df_data['T-Cho'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When you want to extract multiple columns, create a list of column names and use df[[list]]\n",
    "- Note that the list is originally enclosed in [], and then it's enclosed in [] to extract elements, so it results in [[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to extract T-Cho, LDL, HDL, Glu, Y\n",
    "# The idea is to first create a list\n",
    "# Then put that list inside df_data[]\n",
    "# ['T-Cho', 'LDL', 'HDL', 'Glu', 'Y']\n",
    "df_data[['T-Cho', 'LDL', 'HDL', 'Glu', 'Y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here too, you can calculate the mean values in the same way\n",
    "# The mean is calculated only for continuous values\n",
    "df_data[['T-Cho', 'LDL', 'HDL', 'Glu', 'Y']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1\n",
    "- To help you understand the significance of using lists when you want to extract multiple columns in pandas, please execute the following:\n",
    "- Assign 'T-Cho', 'LDL', 'Glu' to a list called a\n",
    "- Try executing df_data[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer\n",
    "# Assign 'T-Cho', 'LDL', 'Glu' to a list called a\n",
    "a =\n",
    "# Display a\n",
    "# If it displays ['T-Cho', 'LDL', 'Glu'], it's correct\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute df_data[a]\n",
    "df_data[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example answer\n",
    "a = ['T-Cho', 'LDL', 'Glu']\n",
    "print(a)\n",
    "df_data[a]\n",
    "# Since a itself is enclosed in [], df[a] is equivalent to df[['Age', 'Subject_Type', 'CSF']]\n",
    "# Until you get used to it, it might be good to consciously create a list first and then put it in df[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting Rows\n",
    "- To extract rows, use loc (**loc**ation) or iloc (**i**nteger **loc**ation)\n",
    "- After loc, specify the value of the index you want to extract\n",
    "- After iloc, specify the row number you want to extract. You can specify multiple rows using slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc can extract rows with specific indexes\n",
    "# Now, the index is ID\n",
    "# Extract ID sub400\n",
    "df_data.loc['sub400']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you specify IDs as a list, you can extract multiple rows\n",
    "df_data.loc[['sub400', 'sub410']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc can extract rows specified by row number\n",
    "# Slicing is the same as Python basics\n",
    "# The row number of the first row is 0\n",
    "# If you want to extract from the 3rd to 5th row, assuming the rows start from 1,\n",
    "# considering the row number starts from 0, you need to extract row numbers 2 to 4,\n",
    "# so think of it as 2 or more and less than 5\n",
    "df_data.iloc[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm by displaying the first 5 rows with df_data.head()\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8. Data Merging\n",
    "#### Horizontal Merging of DataFrames\n",
    "- One of the strengths of pandas is merging tables\n",
    "- In Excel, it can be quite time-consuming when the IDs in two tables don't match perfectly\n",
    "- You can merge tables (DataFrames) horizontally using the pd.merge() function\n",
    "- Specify the common key in the two DataFrames using `on='key'`\n",
    "\n",
    "### Inner Join and Outer Join\n",
    "- There are inner joins and outer joins in merge\n",
    "    - *Strictly speaking, there are three types of outer joins: left, right, and full, but we'll only explain full outer join here\n",
    "- Inner join merges only what is common in the two datasets (in the figure below, only ID04, ID05, ID06 are merged)\n",
    "- Outer join merges all of the two datasets\n",
    "- In mathematical terms, for two groups A and B:\n",
    "    - Inner join is the intersection: A∩B\n",
    "    - Outer join is the union: A∪B\n",
    "\n",
    "<img src=\"https://www.nemotos.net/nb/img/pandas_02.png\" width=300>\n",
    "\n",
    "- By default, only rows with common keys are merged (inner join)\n",
    "\n",
    "- Now, df_demographics has 442 rows, df_data has 442 rows, and df_data_short has 254 rows (imagine some data couldn't be obtained in a research dataset)\n",
    "\n",
    "- We will do three things:\n",
    "    - Merge df_demographics (442 rows) and df_data (442 rows) (This can be done easily in Excel)\n",
    "    - Inner join df_demographics (442 rows) and df_data_short (254 rows) (This is difficult in Excel)\n",
    "    - Outer join df_demographics (442 rows) and df_data_short (254 rows) (This is difficult in Excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_demographics and df_data using the 'ID' key to generate a DataFrame called df\n",
    "df = pd.merge(df_demographics, df_data, on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display only the first 5 rows of df\n",
    "# Note that the columns from demographics and data have been merged\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the size of df\n",
    "# 442 rows and 11 columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_demographics and df_data_short using the 'ID' key to generate a DataFrame called df_short\n",
    "df_short = pd.merge(df_demographics, df_data_short, on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the size of df_short\n",
    "# 254 rows and 11 columns\n",
    "df_short.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display only the first 5 rows of df_short\n",
    "# Note that the number of IDs has decreased\n",
    "df_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform an outer join on df_demographics and df_data_short to generate a DataFrame called df_short_outer\n",
    "# For outer join, specify how='outer'\n",
    "df_short_outer = pd.merge(df_demographics, df_data_short, how='outer', on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the size of df_short_outer\n",
    "# 442 rows and 11 columns\n",
    "df_short_outer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first 5 rows of df_outer\n",
    "# Note that for those without blood data, the blood data items are NaN\n",
    "df_short_outer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9. Handling Missing Values\n",
    "- We'll use df_short_outer to learn about handling missing values\n",
    "- The isnull() method of the DataFrame sets True for values that don't exist and False for others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short_outer.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By using the sum() method on df_short_outer.isnull(), you can find out the number of missing values\n",
    "\n",
    "# Now we can see that there are 190 missing values for each blood data item\n",
    "df_short_outer.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For missing values, there are two options: \"drop\" or \"impute\"\n",
    "\n",
    "# First, let's look at dropping\n",
    "# Execute the dropna() method without arguments\n",
    "df_dropped = df_short_outer.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Originally there were 442, but since there were 190 NaN (Not a Number), it becomes 442 - 190 = 252\n",
    "df_dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For imputation, specify the mean or other values as an argument to the fillna() method\n",
    "df_filled = df_short_outer.fillna(df_short_outer.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN disappears\n",
    "df_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compared to the original, you can see that NaN has been uniformly filled with the mean of each column\n",
    "# Of course, in reality, this method would be inappropriate if there were so many missing values, but it's introduced here as an example\n",
    "df_short_outer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.10. Data Manipulation (2)\n",
    "#### Conditional Extraction\n",
    "- You can also extract only those that meet certain conditions\n",
    "- df['AGE']>40 returns True or False for people older than 40 years\n",
    "- By putting this inside df[], you can create a list of people who meet this condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['AGE'] > 40 returns True or False\n",
    "df['AGE'] > 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By putting the above inside the df index, you can extract only the True ones\n",
    "df[df['AGE'] > 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can create multiple conditions using &, |, ~\n",
    "# Rules:\n",
    "#   You must use one of &, |, ~. You can't use and, or, not\n",
    "#  Each individual condition must be enclosed in ()\n",
    "\n",
    "# Older than 50 and female\n",
    "(df['AGE'] > 50) & (df['SEX'] == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's put this condition inside df[]\n",
    "df[(df['AGE'] > 50) & (df['SEX'] == 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2\n",
    "- We want to extract data where 'AGE' is 40 or older and 'BMI' is 30 or higher. To deepen your understanding, please execute the following:\n",
    "    - Create a condition expression for 'AGE' being 40 or older and assign it to condition1\n",
    "    - Create a condition expression for 'BMI' being 30 or higher and assign it to condition2\n",
    "    - Create a condition expression for condition1 AND condition2 and assign it to b\n",
    "    - Execute df[b] and create a DataFrame called df_b\n",
    "    - Display the first 10 rows of df_b\n",
    "    - Calculate the descriptive statistics of df_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'AGE' 40 or older AND 'BMI' 30 or higher\n",
    "# Hint: 40 or older is >= 40\n",
    "# Hint: AND is &\n",
    "\n",
    "# condition1: 'AGE' is 40 or older\n",
    "condition1 =\n",
    "\n",
    "# Display condition1\n",
    "condition1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition2: 'BMI' is 30 or higher\n",
    "condition2 =\n",
    "# Display condition2\n",
    "condition2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b: condition1 AND condition2\n",
    "b =\n",
    "\n",
    "# Display b\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute df[b] and create a DataFrame called df_b\n",
    "df_b = df[b]\n",
    "\n",
    "# Display the first 10 rows of df_b\n",
    "# Please write below (Hint: head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the descriptive statistics of df_b\n",
    "# Please write below (Hint: describe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Example answer\n",
    "# Question 1\n",
    "df['AGE'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2\n",
    "df[df['SEX'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3\n",
    "df['BMI'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4\n",
    "sns.scatterplot(data=df, x='AGE', y='BMI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5\n",
    "sns.scatterplot(data=df, x='AGE', y='BMI', hue='SEX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6\n",
    "sns.boxplot(data=df, x='SEX', y='BMI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Calculated Values as New Columns\n",
    "- In Pandas, it's easy to calculate items and generate new columns\n",
    "- Not only calculations but also Boolean values can be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Z-score of Glucose\n",
    "# (Glu - mean of Glu) / standard deviation of Glu\n",
    "df['Glu_Z'] = (df['Glu'] - df['Glu'].mean())/df['Glu'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column HC that indicates whether T-cho is greater than 220 or not\n",
    "df['HC'] = df['T-Cho']>220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that HC has been created in the last column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File Output\n",
    "- pandas can easily save to csv or excel\n",
    "- Use the method 'to_file_type'\n",
    "- df.to_csv('filename')\n",
    "- df.to_excel('filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the current df as a file named 'diabetes.xlsx'\n",
    "# It is generated in Google Colaboratory. It can be downloaded\n",
    "df.to_excel('diabetes.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basics of Seaborn\n",
    "- Seaborn can draw various graphs with simple commands\n",
    "- This allows you to visualize relationships in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use seaborn themes, execute the following command\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Rules of Seaborn\n",
    "- After sns, specify the method prepared for each graph\n",
    "    - sns.scatterplot()\n",
    "- Specify the following as arguments:\n",
    "    - data=DataFrame\n",
    "    - x='Item to use for X-axis'\n",
    "    - y='Item to use for Y-axis'\n",
    "    - hue='Item to color-code'\n",
    "    - style='Item to differentiate plot shapes'\n",
    "\n",
    "### 3.1. Basic Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review of df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. scatterplot\n",
    "- Purpose of the graph: Visualize the relationship between two continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=df, x='AGE', y='BMI', hue='SEX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to specify colors, create a dictionary of variable-color correspondences and specify it with palette\n",
    "color_dict = {1: 'blue', 2: 'orange'}  # Example: 1 is male, 2 is female\n",
    "sns.scatterplot(data=df, x='AGE', y='BMI', hue='SEX', palette=color_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. regplot (Scatter plot with regression line)\n",
    "- Purpose of the graph: Visualize the relationship between two continuous variables and their regression line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(data=df, x='AGE', y='BMI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The confidence interval is 95% by default\n",
    "# If you want to change it to 99%, specify ci=99\n",
    "# If you don't need a confidence interval, use ci=None\n",
    "sns.regplot(data=df, x='BMI', y='Glu', ci=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. histplot (Histogram)\n",
    "- Purpose of the graph: Visualize the distribution of variables. Kernel Density Estimation (KDE) can also be added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple histograms can be drawn simultaneously\n",
    "sns.histplot(df[['T-Cho','LDL']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Kernel Density Estimation\n",
    "sns.histplot(data=df, x='Glu', kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Reference)\n",
    "# Unfortunately, plotting a normal distribution curve can't be done with Seaborn alone\n",
    "# Use Matplotlib as follows\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Plot histogram\n",
    "sns.histplot(data=df, x='Glu', stat='density', bins=20)\n",
    "\n",
    "# Calculate normal distribution curve\n",
    "mean = df['Glu'].mean()\n",
    "std = df['Glu'].std()\n",
    "x = np.linspace(df['Glu'].min(), df['Glu'].max(), 100)\n",
    "p = norm.pdf(x, mean, std)\n",
    "\n",
    "# Plot normal distribution curve\n",
    "plt.plot(x, p, 'k', linewidth=1)\n",
    "plt.title('Histogram and Normal Distribution Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. boxplot\n",
    "- Purpose of the graph: Check the dispersion of data and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df[['T-Cho', 'LDL', 'HDL', 'Glu']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E. violinplot\n",
    "- Purpose of the graph: Check the distribution and density of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(df[['T-Cho', 'LDL', 'HDL', 'Glu']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F. swarmplot\n",
    "- Purpose of the graph: Visualize the distribution of data as individual points, used when avoiding overlap of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.swarmplot(data=df, x='SEX', y='BMI', hue='HC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### G. pairplot\n",
    "- Purpose of the graph: Visualize relationships between multiple variables at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[['AGE','BMI','T-Cho','LDL','Glu']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H. heatmap\n",
    "- Purpose of the graph: Visualize a correlation matrix to understand correlations between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, calculate the correlation coefficients between variables and assign to a variable called correlation\n",
    "correlation = df[['AGE','BMI','T-Cho','LDL','Glu']].corr()\n",
    "# Check the contents of correlation\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display correlation as a heatmap\n",
    "# annot=True allows displaying numbers\n",
    "# fmt='.2f' means up to the second decimal place\n",
    "sns.heatmap(correlation, annot=True, fmt='.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I. countplot\n",
    "- Purpose of the graph: Visualize the distribution of categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x='SEX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### J. clustermap\n",
    "- Purpose of the graph: Visualize data clusters to explore patterns and similarities in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(df.corr(), annot=True, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K. Interactive Plot\n",
    "- Purpose of the graph: Interactively manipulate plots to explore relationships in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def plot_scatter(x, y):\n",
    "    sns.scatterplot(data=df, x=x, y=y)\n",
    "\n",
    "interact(plot_scatter, x=df.columns, y=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L. relplot (Relation Plot)\n",
    "- Purpose of the graph: Visualize multiple variables simultaneously to comprehensively understand relationships between variables. Grouping is possible by color (hue), shape (style), and size (size)\n",
    "\n",
    "    ```\n",
    "    sns.relplot(data=DataFrame,\n",
    "                x=column to use for x-axis,\n",
    "                y=column to use for y-axis,\n",
    "                hue=column to change color,\n",
    "                style=column to change the shape of the plot\n",
    "                size=column to reflect in the size of the plot)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simply visualize the relationship between BMI and blood glucose (Glu)\n",
    "sns.relplot(data=df, x='BMI',y='Glu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using hue allows color-coding of groups\n",
    "# Now, color-code groups by presence or absence of hypercholesterolemia\n",
    "sns.relplot(data=df, x='BMI',y='Glu', hue='HC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using style allows differentiation of groups by plot shape\n",
    "# Now, we want to change the shape for men and women\n",
    "sns.relplot(data=df, x='BMI',y='Glu', hue='HC', style='SEX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using size allows changing the size of individual plots\n",
    "# We want to reflect age in the plot\n",
    "sns.relplot(data=df, x=\"BMI\", y=\"Glu\",hue=\"HC\",style=\"SEX\",size=\"AGE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quiz\n",
    "1. Calculate the mean of the 'AGE' column in the df DataFrame\n",
    "2. Find the maximum value of the 'BMI' column in the df DataFrame\n",
    "3. Extract only the data where 'SEX' is 1 from the df DataFrame\n",
    "4. Create a scatter plot showing the relationship between AGE (age) and BMI from the df DataFrame.\n",
    "5. For the scatter plot created in quiz 4, color-code by SEX (gender).\n",
    "6. Create a box plot showing the distribution of BMI by SEX (gender) from the df DataFrame.\n",
    "7. Create a violin plot showing the distribution of BMI by SEX (gender) from the df DataFrame.\n",
    "8. Calculate the correlation matrix of AGE, BMI, T-Cho, LDL, Glu from the df DataFrame.\n",
    "9. Visualize the correlation matrix created in quiz 8 as a heatmap and display the correlation coefficients in each cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 1\n",
    "# Hint: 2.6. Descriptive Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 2\n",
    "# Hint: 2.6. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 3\n",
    "# Hint: 2.7. Data Manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 4\n",
    "# Hint: 3.1.A\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 5\n",
    "# Hint: 3.1.A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 6\n",
    "# Hint: 3.1.D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 7\n",
    "# Hint: 3.1.E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 8\n",
    "# Hint: 2.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 9\n",
    "# Hint: 3.1.H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Example Answers\n",
    "# Quiz 1\n",
    "df['AGE'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 2\n",
    "df[df['SEX'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 3\n",
    "df['BMI'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 4\n",
    "sns.scatterplot(data=df, x='AGE', y='BMI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 5\n",
    "sns.scatterplot(data=df, x='AGE', y='BMI', hue='SEX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 6\n",
    "sns.boxplot(data=df, x='SEX', y='BMI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 7\n",
    "sns.violinplot(data=df, x='SEX', y='BMI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 8\n",
    "correlation = df[['AGE', 'BMI', 'T-Cho', 'LDL', 'Glu']].corr()\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiz 9\n",
    "sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
